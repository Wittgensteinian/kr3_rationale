{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Wittgensteinian--KR3-0f424e029f3cf821\n",
      "Reusing dataset parquet (/home/gsdsaml/.cache/huggingface/datasets/parquet/Wittgensteinian--KR3-0f424e029f3cf821/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "Loading cached processed dataset at /home/gsdsaml/.cache/huggingface/datasets/parquet/Wittgensteinian--KR3-0f424e029f3cf821/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-88ae1594470bd0c3.arrow\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "kr3 = load_dataset(\"Wittgensteinian/KR3\", name='kr3', split='train')\n",
    "kr3 = kr3.remove_columns(['__index_level_0__'])\n",
    "kr3_binary = kr3.filter(lambda example: example['Rating'] != 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 134])\n"
     ]
    }
   ],
   "source": [
    "batch_i = 9\n",
    "attns = torch.load(f'outputs/FT3/attentions/batch_{batch_i}.pt')\n",
    "logits = torch.load(f'outputs/FT3/logits/batch_{batch_i}.pt')\n",
    "print(attns.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0077, 0.0076, 0.0076, 0.0075, 0.0076, 0.0076, 0.0075, 0.0075, 0.0074,\n",
       "         0.0076, 0.0076, 0.0078, 0.0078, 0.0077, 0.0075, 0.0076, 0.0073, 0.0076,\n",
       "         0.0074, 0.0075, 0.0073, 0.0074, 0.0074, 0.0073, 0.0067, 0.0075, 0.0071,\n",
       "         0.0068, 0.0073, 0.0077, 0.0077, 0.0076, 0.0078, 0.0075, 0.0074, 0.0073,\n",
       "         0.0071, 0.0075, 0.0074, 0.0075, 0.0076, 0.0075, 0.0075, 0.0076, 0.0075,\n",
       "         0.0075, 0.0076, 0.0077, 0.0076, 0.0076, 0.0079, 0.0076, 0.0065, 0.0062,\n",
       "         0.0092, 0.0092, 0.0082, 0.0073, 0.0076, 0.0069, 0.0077, 0.0078, 0.0084,\n",
       "         0.0083, 0.0072, 0.0055, 0.0070, 0.0067, 0.0060, 0.0070, 0.0073, 0.0073,\n",
       "         0.0072, 0.0075, 0.0075, 0.0073, 0.0075, 0.0076, 0.0076, 0.0075, 0.0075,\n",
       "         0.0076, 0.0076, 0.0077, 0.0075, 0.0075, 0.0073, 0.0069, 0.0067, 0.0075,\n",
       "         0.0076, 0.0076, 0.0077, 0.0077, 0.0077, 0.0077, 0.0074, 0.0076, 0.0074,\n",
       "         0.0072, 0.0059, 0.0066, 0.0057, 0.0062, 0.0067, 0.0064, 0.0074, 0.0075,\n",
       "         0.0076, 0.0076, 0.0078, 0.0077, 0.0075, 0.0076, 0.0077, 0.0078, 0.0077,\n",
       "         0.0076, 0.0075, 0.0083, 0.0079, 0.0075, 0.0075, 0.0086, 0.0076, 0.0075,\n",
       "         0.0077, 0.0076, 0.0079, 0.0079, 0.0080, 0.0079, 0.0077, 0.0077]),\n",
       " tensor(134))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_i = 15\n",
    "attn = attns[example_i][-1]\n",
    "attn, attn.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer(kr3_binary[batch_i*32 + example_i]['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fresh_extract import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = exclude_cls_sep(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0077, 0.0077, 0.0076, 0.0077, 0.0077, 0.0077, 0.0076, 0.0075,\n",
       "        0.0077, 0.0077, 0.0079, 0.0080, 0.0078, 0.0076, 0.0077, 0.0074, 0.0077,\n",
       "        0.0075, 0.0076, 0.0074, 0.0075, 0.0075, 0.0074, 0.0068, 0.0076, 0.0072,\n",
       "        0.0069, 0.0074, 0.0078, 0.0078, 0.0077, 0.0079, 0.0076, 0.0075, 0.0075,\n",
       "        0.0072, 0.0076, 0.0076, 0.0076, 0.0077, 0.0076, 0.0076, 0.0077, 0.0076,\n",
       "        0.0076, 0.0077, 0.0078, 0.0078, 0.0077, 0.0080, 0.0077, 0.0066, 0.0063,\n",
       "        0.0094, 0.0093, 0.0083, 0.0074, 0.0077, 0.0070, 0.0078, 0.0079, 0.0085,\n",
       "        0.0084, 0.0073, 0.0056, 0.0071, 0.0068, 0.0060, 0.0071, 0.0075, 0.0075,\n",
       "        0.0073, 0.0076, 0.0076, 0.0074, 0.0077, 0.0077, 0.0077, 0.0077, 0.0076,\n",
       "        0.0077, 0.0077, 0.0078, 0.0076, 0.0076, 0.0075, 0.0070, 0.0068, 0.0076,\n",
       "        0.0078, 0.0078, 0.0078, 0.0078, 0.0079, 0.0078, 0.0075, 0.0077, 0.0075,\n",
       "        0.0073, 0.0059, 0.0067, 0.0058, 0.0063, 0.0068, 0.0065, 0.0075, 0.0076,\n",
       "        0.0077, 0.0078, 0.0079, 0.0079, 0.0076, 0.0077, 0.0078, 0.0079, 0.0078,\n",
       "        0.0078, 0.0076, 0.0084, 0.0080, 0.0076, 0.0076, 0.0087, 0.0077, 0.0076,\n",
       "        0.0078, 0.0077, 0.0080, 0.0081, 0.0081, 0.0080, 0.0078, 0.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['여기',\n",
       " '탕수육과',\n",
       " '짜장면,',\n",
       " '맛있다.',\n",
       " '평소',\n",
       " '배달해',\n",
       " '먹던',\n",
       " '중식과',\n",
       " '다른,',\n",
       " '바깥에서',\n",
       " '깔끔한',\n",
       " '중식당에',\n",
       " '갔을',\n",
       " '때',\n",
       " '무심코',\n",
       " '기대해보는',\n",
       " '딱',\n",
       " '그런',\n",
       " '맛.',\n",
       " '무슨',\n",
       " '호텔',\n",
       " '중식당',\n",
       " '이런',\n",
       " '맛에는',\n",
       " '미치지',\n",
       " '못하겠지만',\n",
       " '이',\n",
       " '주변에서',\n",
       " '자신',\n",
       " '있게',\n",
       " '손님을',\n",
       " '데려갈',\n",
       " '수',\n",
       " '있는',\n",
       " '중식당이라면',\n",
       " '여기라고',\n",
       " '생각.',\n",
       " '기본',\n",
       " '식수가',\n",
       " '맹물이',\n",
       " '아닌',\n",
       " '차갑게',\n",
       " '식힌',\n",
       " '국화',\n",
       " '차인',\n",
       " '것도',\n",
       " '좋음.',\n",
       " '식후에는',\n",
       " '입가심으로',\n",
       " '홍초',\n",
       " '물',\n",
       " '같은',\n",
       " '것을',\n",
       " '준다.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = kr3_binary[batch_i*32 + example_i]['Review'].split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor([.1,.1,.1,.0,.0,.0,.0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.nonzero().squeeze()[-1].item()\n",
    "# t[t.nonzero().squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_per_word = get_attn_per_word(attn, words, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0155, 0.0307, 0.0307, 0.0237, 0.0153, 0.0226, 0.0150, 0.0224, 0.0144,\n",
       "        0.0215, 0.0234, 0.0305, 0.0148, 0.0076, 0.0229, 0.0382, 0.0078, 0.0155,\n",
       "        0.0157, 0.0129, 0.0187, 0.0235, 0.0070, 0.0157, 0.0242, 0.0256, 0.0071,\n",
       "        0.0222, 0.0152, 0.0074, 0.0230, 0.0230, 0.0077, 0.0078, 0.0441, 0.0233,\n",
       "        0.0234, 0.0153, 0.0148, 0.0185, 0.0063, 0.0208, 0.0153, 0.0157, 0.0155,\n",
       "        0.0155, 0.0235, 0.0241, 0.0316, 0.0154, 0.0077, 0.0080, 0.0081, 0.0239])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale, unrationale = discretize_attn(attn_per_word, words, strategy='Top-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attn_per_word) == len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['탕수육과',\n",
       " '짜장면,',\n",
       " '중식당에',\n",
       " '기대해보는',\n",
       " '미치지',\n",
       " '못하겠지만',\n",
       " '중식당이라면',\n",
       " '식후에는',\n",
       " '입가심으로',\n",
       " '준다.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['여기',\n",
       " '중식당에',\n",
       " '갔을',\n",
       " '때',\n",
       " '무심코',\n",
       " '기대해보는',\n",
       " '딱',\n",
       " '그런',\n",
       " '맛.',\n",
       " '무슨',\n",
       " '호텔',\n",
       " '중식당',\n",
       " '이런',\n",
       " '맛에는',\n",
       " '미치지',\n",
       " '못하겠지만',\n",
       " '이',\n",
       " '주변에서',\n",
       " '자신',\n",
       " '있게',\n",
       " '손님을',\n",
       " '데려갈',\n",
       " '수',\n",
       " '있는',\n",
       " '중식당이라면',\n",
       " '여기라고',\n",
       " '생각.',\n",
       " '기본',\n",
       " '식수가',\n",
       " '맹물이',\n",
       " '아닌',\n",
       " '차갑게',\n",
       " '식힌',\n",
       " '국화',\n",
       " '차인',\n",
       " '것도',\n",
       " '좋음.',\n",
       " '식후에는',\n",
       " '입가심으로',\n",
       " '홍초',\n",
       " '물',\n",
       " '같은',\n",
       " '것을',\n",
       " '준다.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = kr3_binary[batch_i*32 + example_i]['Rating']\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_item({'Rating':1, 'Rationale':' '.join(rationale), 'Unrationale':' '.join(unrationale)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rating': 1,\n",
       " 'Rationale': '탕수육과 짜장면, 맛있다. 평소 배달해 먹던 중식과 다른, 바깥에서 깔끔한',\n",
       " 'Unrationale': '여기 중식당에 갔을 때 무심코 기대해보는 딱 그런 맛. 무슨 호텔 중식당 이런 맛에는 미치지 못하겠지만 이 주변에서 자신 있게 손님을 데려갈 수 있는 중식당이라면 여기라고 생각. 기본 식수가 맹물이 아닌 차갑게 식힌 국화 차인 것도 좋음. 식후에는 입가심으로 홍초 물 같은 것을 준다.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'여기 탕수육과 짜장면, 맛있다. 평소 배달해 먹던 중식과 다른, 바깥에서 깔끔한 중식당에 갔을 때 무심코 기대해보는 딱 그런 맛. 무슨 호텔 중식당 이런 맛에는 미치지 못하겠지만 이 주변에서 자신 있게 손님을 데려갈 수 있는 중식당이라면 여기라고 생각. 기본 식수가 맹물이 아닌 차갑게 식힌 국화 차인 것도 좋음. 식후에는 입가심으로 홍초 물 같은 것을 준다.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(words)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5333f1ae2d2dec2c1d8a5fd16a6937e3d6f1660c2626f76e133a4bcfc7001c97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('cuda11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
